{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c338d6f9",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "031a2430-7ba4-431f-8e42-e31baf9ce991",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pandas==1.3.4 in /opt/conda/lib/python3.8/site-packages (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from pandas==1.3.4) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas==1.3.4) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers==4.12.5 in /opt/conda/lib/python3.8/site-packages (4.12.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (5.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (1.21.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (2021.10.8)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.0.46)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (0.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.12.5) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.12.5) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.12.5) (2.4.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (2.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.12.5) (1.26.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.12.5) (8.0.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets==1.15.1 in /opt/conda/lib/python3.8/site-packages (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.8.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.70.13)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (0.3.5.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (1.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (9.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (2022.7.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (1.21.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (4.62.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets==1.15.1) (2.26.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.15.1) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets==1.15.1) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.15.1) (3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets==1.15.1) (4.0.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==1.15.1) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets==1.15.1) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets==1.15.1) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (7.7.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.6.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.28.0)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (58.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.2.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.3.4\n",
    "!pip install transformers==4.12.5\n",
    "!pip install datasets==1.15.1\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7596a57f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "db736e14-03fb-4438-938d-c705d6786666",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import ClassLabel\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c116e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60f5fd90",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "37286c02-6bf4-41f5-ab70-51515a054e7b",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61aa788a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "0c699094-439f-4dda-85a9-815e7948540c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/notebooks/Data/bert_sequence_classification'\n",
    "DATA_FILE = '/notebooks/linguistic_features/data/hf_datasets/pe_dataset_linguistic_features.pt'\n",
    "RESULTS_FOLDER = '/notebooks/Results/bert_sequence_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d032dd",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "35aada91-232a-421e-a28f-94b359c6d65d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee17a90",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "dc52e71e-65fa-4946-acdf-e4fffe9d0f79",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd6026d",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "d352c1cd-abff-4b1e-b5e2-611288e4fddb",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ed1d3a1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "013a6d64-65e7-4189-a468-40ecfd8a6736",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effed29e",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "626737f9-ff56-4992-b72b-60750375e455",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset = torch.load(DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45e81ca",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "4fbfcc7b-55fb-456e-ab02-2ae975803046",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['essay_nr', 'component_id', 'label_and_comp_idxs', 'text', 'label_x', 'label_ComponentType', 'relation_SupportAttack', 'label_RelationType', 'label_LinkedNotLinked', 'split', 'essay', 'argument_bound_1', 'argument_bound_2', 'argument_id', 'sentence', 'paragraph', 'para_nr', 'total_paras', 'token_count', 'token_count_covering_para', 'tokens_count_covering_sentence', 'preceeding_tokens_in_sentence_count', 'succeeding_tokens_in_sentence_count', 'token_ratio', 'relative_position_in_para_char', 'is_in_intro', 'relative_position_in_para_token', 'is_in_conclusion', 'is_first_in_para', 'is_last_in_para', 'nr_preceeding_comps_in_para', 'nr_following_comps_in_para', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'component_POS', 'strct_fts_and_component_pos', 'sentence_POS', 'strct_fts_and_sentence_pos', 'component_syn_deps', 'strct_fts_and_component_syn_deps', 'sentence_syn_deps', 'strct_fts_and_sentence_syn_deps', 'strct_pos_syn_deps_component', 'strct_pos_syn_deps_sentence'],\n",
       "        num_rows: 3770\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['essay_nr', 'component_id', 'label_and_comp_idxs', 'text', 'label_x', 'label_ComponentType', 'relation_SupportAttack', 'label_RelationType', 'label_LinkedNotLinked', 'split', 'essay', 'argument_bound_1', 'argument_bound_2', 'argument_id', 'sentence', 'paragraph', 'para_nr', 'total_paras', 'token_count', 'token_count_covering_para', 'tokens_count_covering_sentence', 'preceeding_tokens_in_sentence_count', 'succeeding_tokens_in_sentence_count', 'token_ratio', 'relative_position_in_para_char', 'is_in_intro', 'relative_position_in_para_token', 'is_in_conclusion', 'is_first_in_para', 'is_last_in_para', 'nr_preceeding_comps_in_para', 'nr_following_comps_in_para', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'component_POS', 'strct_fts_and_component_pos', 'sentence_POS', 'strct_fts_and_sentence_pos', 'component_syn_deps', 'strct_fts_and_component_syn_deps', 'sentence_syn_deps', 'strct_fts_and_sentence_syn_deps', 'strct_pos_syn_deps_component', 'strct_pos_syn_deps_sentence'],\n",
       "        num_rows: 1260\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['essay_nr', 'component_id', 'label_and_comp_idxs', 'text', 'label_x', 'label_ComponentType', 'relation_SupportAttack', 'label_RelationType', 'label_LinkedNotLinked', 'split', 'essay', 'argument_bound_1', 'argument_bound_2', 'argument_id', 'sentence', 'paragraph', 'para_nr', 'total_paras', 'token_count', 'token_count_covering_para', 'tokens_count_covering_sentence', 'preceeding_tokens_in_sentence_count', 'succeeding_tokens_in_sentence_count', 'token_ratio', 'relative_position_in_para_char', 'is_in_intro', 'relative_position_in_para_token', 'is_in_conclusion', 'is_first_in_para', 'is_last_in_para', 'nr_preceeding_comps_in_para', 'nr_following_comps_in_para', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'component_POS', 'strct_fts_and_component_pos', 'sentence_POS', 'strct_fts_and_sentence_pos', 'component_syn_deps', 'strct_fts_and_component_syn_deps', 'sentence_syn_deps', 'strct_fts_and_sentence_syn_deps', 'strct_pos_syn_deps_component', 'strct_pos_syn_deps_sentence'],\n",
       "        num_rows: 943\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4291c5",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "57c21a2e-83cd-4f4b-a19a-0bae29eb4794",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Topic: Young people should go to university or not, Sentence: Although higher education does not guarantee young students' success, the benefits of learning in universities are the vital factor in creating more possibilities for the development of society through advancing academic fulfillment and the young generation who have experiences and challenges., Para Number: 4, First in Para: No, Last in Para: Yes, Is in Introduction: No, Is in Conclusion: Yes. Part Of Speech tags: DET, NOUN, ADP, VERB, ADP, NOUN, AUX, DET, ADJ, NOUN, ADP, VERB, ADJ, NOUN, ADP, DET, NOUN, ADP, NOUN, ADP, VERB, ADJ, NOUN, CCONJ, DET, ADJ, NOUN, PRON, AUX, NOUN, CCONJ, NOUN\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['strct_fts_and_component_pos'][230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12fe86d5",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "492e0415-2634-47bb-88bf-665c130d032c",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60fa137a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "ba2c9132-d013-4b26-be96-146cf024a45e",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "label_names = set(dataset['train']['label_ComponentType'])\n",
    "label_nb = len(label_names)\n",
    "labels = ClassLabel(num_classes=label_nb, names=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34374a2b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 10,
     "id": "2f1ce51b-18bc-40db-983f-3434b8651e45",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(num_classes=3, names={'Premise', 'MajorClaim', 'Claim'}, names_file=None, id=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a292e2b2",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 11,
     "id": "5438b78c-249c-48ac-98e8-a87a2cc0c86d",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    tokens = tokenizer(batch['strct_fts_and_component_pos'], truncation=True, padding=True, max_length=512)\n",
    "    tokens['labels'] = labels.str2int(batch['label_ComponentType'])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7477c8",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 12,
     "id": "cb8d8c9a-7539-4d02-9dc5-98bade787549",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x7f2894059700> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274c0b64720e4900bda2c806b86d05f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba3a2be52a54a9994200138663bbc74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1937fffeb36a4e8c8cec60d35016014d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f55645a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 13,
     "id": "84abf830-f842-4e91-8d5c-7fcd9ea2942e",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0abea972",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 14,
     "id": "c7d70e98-c2e0-4055-9d52-74c67c199c72",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['argument_bound_1', 'argument_bound_2', 'argument_id', 'attention_mask', 'component_POS', 'component_id', 'component_syn_deps', 'essay', 'essay_nr', 'input_ids', 'is_first_in_para', 'is_in_conclusion', 'is_in_intro', 'is_last_in_para', 'label_ComponentType', 'label_LinkedNotLinked', 'label_RelationType', 'label_and_comp_idxs', 'label_x', 'labels', 'nr_following_comps_in_para', 'nr_preceeding_comps_in_para', 'para_nr', 'paragraph', 'preceeding_tokens_in_sentence_count', 'relation_SupportAttack', 'relative_position_in_para_char', 'relative_position_in_para_token', 'sentence', 'sentence_POS', 'sentence_syn_deps', 'split', 'strct_fts_and_component_pos', 'strct_fts_and_component_syn_deps', 'strct_fts_and_sentence_pos', 'strct_fts_and_sentence_syn_deps', 'strct_pos_syn_deps_component', 'strct_pos_syn_deps_sentence', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'succeeding_tokens_in_sentence_count', 'text', 'token_count', 'token_count_covering_para', 'token_ratio', 'token_type_ids', 'tokens_count_covering_sentence', 'total_paras'],\n",
       "        num_rows: 3770\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['argument_bound_1', 'argument_bound_2', 'argument_id', 'attention_mask', 'component_POS', 'component_id', 'component_syn_deps', 'essay', 'essay_nr', 'input_ids', 'is_first_in_para', 'is_in_conclusion', 'is_in_intro', 'is_last_in_para', 'label_ComponentType', 'label_LinkedNotLinked', 'label_RelationType', 'label_and_comp_idxs', 'label_x', 'labels', 'nr_following_comps_in_para', 'nr_preceeding_comps_in_para', 'para_nr', 'paragraph', 'preceeding_tokens_in_sentence_count', 'relation_SupportAttack', 'relative_position_in_para_char', 'relative_position_in_para_token', 'sentence', 'sentence_POS', 'sentence_syn_deps', 'split', 'strct_fts_and_component_pos', 'strct_fts_and_component_syn_deps', 'strct_fts_and_sentence_pos', 'strct_fts_and_sentence_syn_deps', 'strct_pos_syn_deps_component', 'strct_pos_syn_deps_sentence', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'succeeding_tokens_in_sentence_count', 'text', 'token_count', 'token_count_covering_para', 'token_ratio', 'token_type_ids', 'tokens_count_covering_sentence', 'total_paras'],\n",
       "        num_rows: 1260\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['argument_bound_1', 'argument_bound_2', 'argument_id', 'attention_mask', 'component_POS', 'component_id', 'component_syn_deps', 'essay', 'essay_nr', 'input_ids', 'is_first_in_para', 'is_in_conclusion', 'is_in_intro', 'is_last_in_para', 'label_ComponentType', 'label_LinkedNotLinked', 'label_RelationType', 'label_and_comp_idxs', 'label_x', 'labels', 'nr_following_comps_in_para', 'nr_preceeding_comps_in_para', 'para_nr', 'paragraph', 'preceeding_tokens_in_sentence_count', 'relation_SupportAttack', 'relative_position_in_para_char', 'relative_position_in_para_token', 'sentence', 'sentence_POS', 'sentence_syn_deps', 'split', 'strct_fts_and_component_pos', 'strct_fts_and_component_syn_deps', 'strct_fts_and_sentence_pos', 'strct_fts_and_sentence_syn_deps', 'strct_pos_syn_deps_component', 'strct_pos_syn_deps_sentence', 'structural_fts_as_text', 'structural_fts_as_text_combined', 'succeeding_tokens_in_sentence_count', 'text', 'token_count', 'token_count_covering_para', 'token_ratio', 'token_type_ids', 'tokens_count_covering_sentence', 'total_paras'],\n",
       "        num_rows: 943\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5783531",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 15,
     "id": "e825c71a-23f8-4794-b114-729819def9ab",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset['train'].shuffle(seed=42)\n",
    "test_dataset = dataset['test'].shuffle(seed=42)\n",
    "\n",
    "train_val_datasets = dataset['train'].train_test_split(train_size=0.8, seed=42)\n",
    "train_dataset = train_val_datasets['train']\n",
    "val_dataset = train_val_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90798f4d",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 16,
     "id": "e13433b1-343d-417d-bfbd-8bacb4c57d23",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "dataset_d = {}\n",
    "dataset_d['train'] = train_dataset\n",
    "dataset_d['test'] = test_dataset\n",
    "dataset_d['val'] = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9896115f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 17,
     "id": "a298a871-1a0d-4ed8-9a1c-1ed3795f1d74",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] topic : zoos have no useful purpose?, sentence : in the zoo you can see an animal and their different variations, the male and the female or the baby and the adult, para number : 3, first in para : no, last in para : no, is in introduction : no, is in conclusion : no. part of speech tags : adp, det, noun, pron, verb, verb, det, noun, cconj, det, adj, noun, punct, det, noun, cconj, det, noun, cconj, det, noun, cconj, det, noun [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset['train'][2945]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6248008",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 18,
     "id": "aa1384b3-bd47-41a3-86b1-9cf814d47cdf",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['train']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfcf18f8",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 19,
     "id": "84df366a-6334-4e3a-902b-deb1c99491fb",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRAIN'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['val']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b2b5200",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 20,
     "id": "406ad783-a570-4c26-8aa6-243e866b6fbf",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TEST'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "set(dataset_d['test']['split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b76541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "NUM_LABELS = labels.num_classes\n",
    "BATCH_SIZE = 24\n",
    "NB_EPOCHS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a527e3e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbf9625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(dataset_d['train']['labels'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6db16b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [max(counter.values()) / counter[k] for k in sorted(counter.keys())]\n",
    "class_weights = torch.FloatTensor(class_weights)#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "062eb45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 5.3056, 2.5603])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df06f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = torch.sum(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed473ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_weights = [class_weights[i] / total_weights for i in [0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82bae42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_weights = torch.FloatTensor(norm_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9827b4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1128, 0.5984, 0.2888])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3ad2c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMacroF1(nn.Module):\n",
    "    \n",
    "    def __init__(self, weights):\n",
    "        super(SoftMacroF1, self).__init__()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        Computes differentiable macro F1 score.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions : torch.Tensor\n",
    "            tensor of predictions (float, 2D)\n",
    "\n",
    "        targets : torch.Tensor\n",
    "            tensor of targets (integers, 1D)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cost : torch.Tensor\n",
    "            1 - differentiable macro F1 (0D, i.e., value)\n",
    "        \"\"\"\n",
    "        dim = predictions.shape[1]\n",
    "        soft_f1s = torch.zeros(size=(dim,))\n",
    "        \n",
    "        predictions = torch.nn.Softmax(dim=1)(predictions)\n",
    "\n",
    "        for i in range(dim):\n",
    "\n",
    "            targets_tmp = targets == i\n",
    "\n",
    "            targets_tmp = targets_tmp.float()\n",
    "            #predictions_i = predictions[:, i].float()\n",
    "\n",
    "            tp = torch.sum(predictions[:, i] * targets_tmp, axis=0)\n",
    "            fp = torch.sum(predictions[:, i] * (1 - targets_tmp), axis=0)\n",
    "            fn = torch.sum((1 - predictions[:, i]) * targets_tmp, axis=0)\n",
    "            soft_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "            soft_f1s[i] = soft_f1\n",
    "            \n",
    "        #macro_f1 = torch.div((soft_f1s @ self.weights), len(soft_f1s)) # weighted\n",
    "        \n",
    "        macro_f1 = soft_f1s @ self.weights\n",
    "\n",
    "        # macro_f1 = torch.mean(soft_f1s, axis=0) # simgple\n",
    "        \n",
    "        # special_macro_f1 = torch.weighted_mean(soft_f1s, axis=0, weights=[0.4, 0.5, 0.1])\n",
    "\n",
    "        cost = 1 - macro_f1 # reduce 1 - soft-f1 in order to increase soft-f1\n",
    "\n",
    "        #macro_cost = tf.reduce_mean(cost) # average on all labels\n",
    "\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56935db5",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 27,
     "id": "521987db-56d5-4e71-95af-7d1fb4a06e3f",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/transformers/main_classes/trainer.html\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = SoftMacroF1(weights=class_weights)#nn.CrossEntropyLoss()#(weight=class_weights)\n",
    "        # added softmax here. but then put it in the loss class.\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45f05c5b",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 28,
     "id": "06697293-0ef4-4d24-95a9-6ca0ed569b51",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return metric.compute(predictions=predictions, references=labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca9e5aba",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 29,
     "id": "956f8a45-f8bd-42a5-b829-5e2b0e82cf42",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \n",
    "    # output\n",
    "    output_dir=RESULTS_FOLDER,          \n",
    "    \n",
    "    #params\n",
    "    num_train_epochs=NB_EPOCHS,               # nb of epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # cf. paper Sun et al.\n",
    "    learning_rate=1e-5,#2e-5,                 # cf. paper Sun et al.\n",
    "#     warmup_steps=500,                         # number of warmup steps for learning rate scheduler\n",
    "    warmup_ratio=0.1,                         # cf. paper Sun et al.\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    \n",
    "    #eval\n",
    "    evaluation_strategy=\"steps\",              # cf. paper Sun et al.\n",
    "    eval_steps=20,                            # cf. paper Sun et al.\n",
    "    \n",
    "    # log\n",
    "    logging_dir=\"/notebooks/linguistic_features/notebooks/CustLoss_TF_Results\",  \n",
    "    logging_strategy='steps',\n",
    "    logging_steps=20,\n",
    "    \n",
    "    # save\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=2,\n",
    "    #save_steps=20, # default 500\n",
    "    load_best_model_at_end=True,              # cf. paper Sun et al.\n",
    "    # metric_for_best_model='eval_loss' \n",
    "    metric_for_best_model='f1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "819c1c31",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 30,
     "id": "219545f7-5aff-4d0c-87e2-4ca28a6e7acc",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    }
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer( # Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf49a563",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 31,
     "id": "b524a80a-ccf0-41f4-a015-e4ba2913fdc4",
     "kernelId": "5ae81875-6bf9-4a4d-b9d2-28830bffd5f4"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running training *****\n",
      "  Num examples = 3016\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 24\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 24\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 756\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='756' max='756' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [756/756 13:32, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>-1.081800</td>\n",
       "      <td>-1.074124</td>\n",
       "      <td>0.074862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>-1.009100</td>\n",
       "      <td>-1.154821</td>\n",
       "      <td>0.468048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>-1.078200</td>\n",
       "      <td>-1.466393</td>\n",
       "      <td>0.466660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>-1.737800</td>\n",
       "      <td>-2.790278</td>\n",
       "      <td>0.644951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>-2.688800</td>\n",
       "      <td>-3.891407</td>\n",
       "      <td>0.650864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>-3.876500</td>\n",
       "      <td>-4.466651</td>\n",
       "      <td>0.712125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>-3.760200</td>\n",
       "      <td>-4.426193</td>\n",
       "      <td>0.698088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>-4.242000</td>\n",
       "      <td>-4.856114</td>\n",
       "      <td>0.712656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>-4.497400</td>\n",
       "      <td>-4.815828</td>\n",
       "      <td>0.691450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>-5.038000</td>\n",
       "      <td>-4.769930</td>\n",
       "      <td>0.716208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>-4.583100</td>\n",
       "      <td>-5.118333</td>\n",
       "      <td>0.697136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>-4.495700</td>\n",
       "      <td>-5.256999</td>\n",
       "      <td>0.747933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>-4.787900</td>\n",
       "      <td>-5.180996</td>\n",
       "      <td>0.723759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>-4.986700</td>\n",
       "      <td>-5.055852</td>\n",
       "      <td>0.742386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>-4.895700</td>\n",
       "      <td>-5.381531</td>\n",
       "      <td>0.730912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>-4.860800</td>\n",
       "      <td>-5.277965</td>\n",
       "      <td>0.741875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>-5.308800</td>\n",
       "      <td>-5.256318</td>\n",
       "      <td>0.738456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>-5.587400</td>\n",
       "      <td>-5.282692</td>\n",
       "      <td>0.744371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>-5.636200</td>\n",
       "      <td>-5.396952</td>\n",
       "      <td>0.749686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>-5.151600</td>\n",
       "      <td>-5.484012</td>\n",
       "      <td>0.743811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>-4.965400</td>\n",
       "      <td>-5.390408</td>\n",
       "      <td>0.749036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>-5.355700</td>\n",
       "      <td>-5.337188</td>\n",
       "      <td>0.740836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>-4.923100</td>\n",
       "      <td>-5.386302</td>\n",
       "      <td>0.747115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>-5.059300</td>\n",
       "      <td>-5.423428</td>\n",
       "      <td>0.752025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>-5.756100</td>\n",
       "      <td>-5.432558</td>\n",
       "      <td>0.749748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>-5.148700</td>\n",
       "      <td>-5.268433</td>\n",
       "      <td>0.732736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>-4.652100</td>\n",
       "      <td>-5.402650</td>\n",
       "      <td>0.738675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>-5.708900</td>\n",
       "      <td>-5.424537</td>\n",
       "      <td>0.748296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>-5.960000</td>\n",
       "      <td>-5.324812</td>\n",
       "      <td>0.746732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>-5.326500</td>\n",
       "      <td>-5.367638</td>\n",
       "      <td>0.745829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>-5.404100</td>\n",
       "      <td>-5.384859</td>\n",
       "      <td>0.747706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>-5.822500</td>\n",
       "      <td>-5.315258</td>\n",
       "      <td>0.745732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>-5.657000</td>\n",
       "      <td>-5.358122</td>\n",
       "      <td>0.746793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>-5.855100</td>\n",
       "      <td>-5.347239</td>\n",
       "      <td>0.744911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>-5.335200</td>\n",
       "      <td>-5.422653</td>\n",
       "      <td>0.750688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>-5.790700</td>\n",
       "      <td>-5.436500</td>\n",
       "      <td>0.750866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>-5.287900</td>\n",
       "      <td>-5.421899</td>\n",
       "      <td>0.749255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "Saving model checkpoint to /notebooks/Results/bert_sequence_classification/checkpoint-500\n",
      "Configuration saved in /notebooks/Results/bert_sequence_classification/checkpoint-500/config.json\n",
      "Model weights saved in /notebooks/Results/bert_sequence_classification/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in /notebooks/Results/bert_sequence_classification/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in /notebooks/Results/bert_sequence_classification/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 754\n",
      "  Batch size = 24\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /notebooks/Results/bert_sequence_classification/checkpoint-500 (score: 0.749748483944726).\n"
     ]
    }
   ],
   "source": [
    "results = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb4501e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b3bb7d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9239c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: is_first_in_para, label_and_comp_idxs, total_paras, para_nr, strct_fts_and_component_pos, component_id, label_x, essay_nr, strct_fts_and_sentence_pos, is_in_intro, nr_following_comps_in_para, nr_preceeding_comps_in_para, strct_pos_syn_deps_component, paragraph, component_syn_deps, strct_fts_and_component_syn_deps, token_count_covering_para, label_RelationType, label_ComponentType, relation_SupportAttack, argument_id, is_last_in_para, argument_bound_1, sentence_POS, succeeding_tokens_in_sentence_count, argument_bound_2, token_ratio, preceeding_tokens_in_sentence_count, component_POS, is_in_conclusion, structural_fts_as_text, strct_fts_and_sentence_syn_deps, text, label_LinkedNotLinked, relative_position_in_para_char, split, strct_pos_syn_deps_sentence, token_count, essay, sentence, sentence_syn_deps, relative_position_in_para_token, structural_fts_as_text_combined, tokens_count_covering_sentence.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1260\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='158' max='158' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [158/158 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_trainer = Trainer(model, data_collator=DataCollatorWithPadding(tokenizer))\n",
    "test_raw_preds, test_labels, _ = test_trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_raw_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11861801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1260"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dbc9135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Premise      0.891     0.906     0.898       805\n",
      "  MajorClaim      0.757     0.915     0.828       153\n",
      "       Claim      0.669     0.570     0.615       302\n",
      "\n",
      "    accuracy                          0.826      1260\n",
      "   macro avg      0.772     0.797     0.781      1260\n",
      "weighted avg      0.822     0.826     0.822      1260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_name = labels.int2str([0,1,2])\n",
    "print(classification_report(test_labels, test_preds, target_names=target_name, digits=3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58fd097c",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "     Premise      0.891     0.906     0.898       805\n",
    "  MajorClaim      0.757     0.915     0.828       153\n",
    "       Claim      0.669     0.570     0.615       302\n",
    "\n",
    "    accuracy                          0.826      1260\n",
    "   macro avg      0.772     0.797     0.781      1260\n",
    "weighted avg      0.822     0.826     0.822      1260\n",
    "\n",
    "w/o division by three"
   ]
  },
  {
   "cell_type": "raw",
   "id": "530935c2",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.514     0.811     0.629       302\n",
    "     Premise      0.955     0.740     0.834       805\n",
    "  MajorClaim      0.799     0.830     0.814       153\n",
    "\n",
    "    accuracy                          0.768      1260\n",
    "   macro avg      0.756     0.794     0.759      1260\n",
    "weighted avg      0.830     0.768     0.783      1260\n",
    "\n",
    "w normalized weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd8149c8",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.630     0.715     0.670       302\n",
    "     Premise      0.935     0.856     0.894       805\n",
    "  MajorClaim      0.767     0.902     0.829       153\n",
    "\n",
    "    accuracy                          0.828      1260\n",
    "   macro avg      0.777     0.824     0.797      1260\n",
    "weighted avg      0.841     0.828     0.832      1260\n",
    "\n",
    "w normal weights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14538cd9",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "       Claim      0.704     0.662     0.683       302\n",
    "  MajorClaim      0.770     0.961     0.855       153\n",
    "     Premise      0.922     0.899     0.911       805\n",
    "\n",
    "    accuracy                          0.850      1260\n",
    "   macro avg      0.799     0.841     0.816      1260\n",
    "weighted avg      0.851     0.850     0.849      1260\n",
    "\n",
    "field used: strct_fts_and_component_pos, 1e-5, 48, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b91de52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "238ce718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[729,   3,  73],\n",
       "       [  1, 140,  12],\n",
       "       [ 88,  42, 172]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f32ac39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a4eb52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2990674580>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a68b0592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 2, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "253f7507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
